---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Dr. Lianli Gao(È´òËÅî‰∏Ω) is a Professor in School of Computer Science and Engineering (CSE) at University of Electronic Science and Technology of China (UESTC). Dr. Gao received her Ph.D in School of Electronic Engineering and Computer Science (ITEE) at University of Queensland in 2014 (under the supervision of [Prof. Jane Hunter](https://staff.itee.uq.edu.au/jane/), [Prof. Michael Bruenig](https://researchers.uq.edu.au/researcher/5052) and [A/Prof. Yuan-Fang Li](https://users.monash.edu.au/~yli/) and her B.CS. in School of Computer Science and Engineering (CSE) at University of Electronic Science and Technology of China (UESTC) in 2009, respectively.

Dr. Gao is the leader of the  Multimedia Analysis and Visual Cognition research group. She has a strong ability to develop and author successful grant funding proposals in close collaboration with industry, government partners, and colleagues within and across universities. Her research has been supported by 12 nationally competitive research grants, including one Major Project from the Ministry of Science and Technology of China, two key projects from the National Natural Science Foundation of China, four projects from the industry, etc. In addition, she has served or will serve as ECCV Area Chair 2024, WACV Area Chair 2022-2024, program committee of the IJCAI 24 track on AI and Social Good, AAAI SPC 2022, ACM MM 2021 Session Chair, ACM MM 2021 Workshop Co-chair, IJCAI Session Chair 2019, Guest Editor of 2019 Journal of Visual Communication and Image Representation, etc.

Her research interests include multimedia understanding, computer vision,  artificial intelligence, and machine learning, and published over 160 publications at prestigious journals and proceedings in prominent conferences (including 70+ IEEE/ACM Transactions and 70+ CCF-A papers (Chinese Computing Federation A ranked (e.g., CVPR, ICCV, NeurIPS, ICML, and ICLR)). Her publications have been cited in Google Scholar more than 7,400 times, and her H-Index in Google Scholar is 44. She has received Best Student Paper Award from Australasian Database Conference 2017, Rising Star Award from IEEE Technical Community on Multimedia Computing 2020, Sichuan Provincial Academic/Technical Leader (Reserve Candidate) 2021, UESTC Research Excellence Award (2018, 2020,2023), Alibaba DAMO Academy Young Fellow Award 2019, Rising Star of Science Award 2023, and also has been selected as one of the 2023 Chinese Young Female Scholars in Artificial Intelligence for her outstanding academic performance in AI. In terms of international challenges she received ICCV  Deeper Action 3rd Place Award in Kinetics-TPS Challenge on Part-level Action Parsing 2021, CVPR Security AI Challenger Phrase VI Track 1st Place award in White-box Adversarial Attacks on ML Defense Models 2021, ICCV COCO DensePose Challenge 2nd place award 2019, OPPO Security Challenge 2nd Place 2021, and ECCV DeeperAction Track4 3nd Place 2022, etc. 

<!-- 
Her Teaching covers a wide range of courses at different levels for both international and national students, including "Introduction to Big Data", "Data Structure and Algorithm", "Introduction to Computer Vision", "Semantic Web", "Experiments of Artificial Intelligence", "Welcome to Academic World" etc. She received very positive feedback (e.g., "nice teacher", "well-organized", "good experience" and "dedicated to providing us with knowledge‚Äú) from her students with a well-deserved 5-star rating. In addition, she has been mentoring junior staff by assessing peer-to-peer teaching performance via attending their classes. Her dedication earned her Excellent Faculty Award for Outstanding Teaching in 2018 and 2023.
-->

# üî• Hire
 We consistently have open positions available for Professors, Associate Professors, Lecturers, Postdocs, and PhD students. If you are interested Feel free to reach out to me via email.
  
# üî• News
<!-- - *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->
- *2024.10*: &nbsp; Two papers accepted by NeurIPS 2024!
- *2024.09*: &nbsp; Serve as Associate Editor of IEEE TMM!
- *2024.08*: &nbsp; Best Paper Candidate of ICME 2024!
- *2024.02*: &nbsp; Two papers were accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)!
- *2024.01*: &nbsp; Four papers were accepted by IEEE Transactions on Multimedia (TMM 2024)!
- *2023.10*: &nbsp; One paper was accepted by IEEE Transactions on Image Processing (TIP 2023)!
- *2023.09*: &nbsp; One paper was accepted by Annual Conference on Neural Information Processing Systems (NeurIPS 2023)!
- *2023.07*: &nbsp; Four papers were accepted by ACM Multimedia (MM 2023)!
- *2023.07*: &nbsp; One paper was accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI 2023)!
- *2023.05*: &nbsp; Two papers were accepted by IEEE/CVF International Conference on Computer Vision (ICCV 2023)!
- *2023.03*: &nbsp; One paper was accepted by IEEE Transactions on Image Processing (TIP 2023)!
- *2023.02*: &nbsp; One paper was accepted by IEEE Transactions on Image Processing (TIP 2023)!


# üìù Publications 
Here are some **selective publications**. For **full publications**, please visit my [Google Scholar](https://scholar.google.com/citations?user=zsm2dpYAAAAJ) and [DBLP](https://dblp.org/pid/123/9849.html).



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCV 2024</div><img src='images/papers/ijcv.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Informative scene graph generation via debiasing.**](https://arxiv.org/pdf/2308.05286.pdf) \\
 **Lianli Gao**, X. Lyu, Y. Guo, Y. Hu, Y.-F. Li, L. Xu, H. T. Shen, and J. Song.
_ArXiv_ (****), 2024\\
 <a href="https://arxiv.org/pdf/2308.05286.pdf"><strong>Paper</strong></a>
\|
<a href="https://github.com/ZhuGeKongKong/SGG-G2S"><strong>Code</strong></a>

**Making balanced and informative predicate prediction for SGG.**

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/papers/1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Dept: Decoupled prompt tuning.**](https://arxiv.org/pdf/2309.07439.pdf) \\
J. Zhang, S. Wu, **Lianli Gao**, H. T. Shen, and J. Song.\\
In _IEEE/CVF Conference on Computer Vision and Pattern Recognition_ (**CVPR**), 2024\\
 <a href="https://ieeexplore.ieee,org/stamp/stamp.jsp?arnumber=9969654"><strong>Paper</strong></a>
\|
<a href="https://github.com/Koorye/DePT"><strong>Code</strong></a>

**Overcoming base-new trade-off problem for existing prompt tuning methods.**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/papers/2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Prog: Prompting-to simulate generalized knowledge for universal cross-domain retrieval.**](https://arxiv.org/pdf/2312.12478.pdf) \\
K. Fang, J. Song, **Lianli Gao**, P. Zeng, Z.-Q. Cheng, X. Li, and H. T. Shen. \\
In _IEEE/CVF Conference on Computer Vision and Pattern Recognition_ (**CVPR**), 2024\\
 <a href="https://arxiv.org/pdf/2312.12478.pdf"><strong>Paper</strong></a>
\|
<a href="https://github.com/fangkaipeng/ProS"><strong>Code</strong></a>

**Applying prompt tuning to produce generalized features for UCDR.**

</div>
</div>







<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI 2023</div><img src='images/papers/4.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Label-guided generative adversarial network for realistic image synthesis.**](https://users.monash.edu/~yli/assets/pdf/img_syn_tpami2022.pdf) \\
J. Zhu, **Lianli Gao**, J. Song, Y. Li, F. Zheng, X. Li, and H. T. Shen.\\
_IEEE Trans. Pattern Anal. Mach. Intell._ (**TPAMI**), 45(3):3311‚Äì3328, 2023\\
 <a href="https://users.monash.edu/~yli/assets/pdf/img_syn_tpami2022.pdf"><strong>Paper</strong></a>
\|
<a href="https://github.com/RoseRollZhu/Lab2Pix-V2"><strong>Code</strong></a>
 
**Bridging semantic gap between labels and images for Label-Image Generation.**

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI 2023</div><img src='images/papers/tpami.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Adaptive fine-grained predicates learning for scene graph generation.**](https://arxiv.org/pdf/2207.04602.pdf) \\
X. Lyu, **Lianli Gao**, P. Zeng, H. T. Shen, and J. Song.\\
_IEEE Trans. Pattern Anal. Mach. Intell._ (**TPAMI**), 45(11):13921‚Äì13940, 2023\\
 <a href="https://arxiv.org/pdf/2207.04602.pdf"><strong>Paper</strong></a>
\|
<a href="https://github.com/XinyuLyu/FGPL"><strong>Code</strong></a>

**Ensuring balanced and efficient learning process for fine-grained SGG.**
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2023</div><img src='images/papers/5.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**A closer look at few-shot classification again.**](https://arxiv.org/pdf/2301.12246.pdf) \\
 X. Luo, H. Wu, J. Zhang, **Lianli Gao**, J. Xu, and J. Song.\\
In _International Conference on Machine Learning_ (**ICML**), pages 23103‚Äì23123, 2023\\
<a href="https://arxiv.org/pdf/2301.12246.pdf"><strong>Paper</strong></a>
\|
<a href="https://github.com/Frankluox/CloserLookAgainFewShot"><strong>Code</strong></a>

**Empirically proving disentanglement of training and test-time adaptation algorithms in FSL.**

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIP 2023</div><img src='images/papers/6.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Toward a unified transformer-based framework for scene graph generation and human-obfect interaction detection.**](https://arxiv.org/pdf/2311.01755.pdf)  \\
T. He, **Lianli Gao**, J. Song, and Y. Li. \\
_IEEE Trans. Image Process._ (**TIP**), 32:6274‚Äì6288, 2023\\
<a href="https://arxiv.org/pdf/2311.01755.pdf"><strong>Paper</strong></a>
\|
<a href="https://lianligao,github.io/"><strong>Code</strong></a>

**Build a Unified Transformer-based Framework for SGG and HOI.**

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/papers/cvpr23.png' alt="sym" width="100%" height="125%"></div></div>
<div class='paper-box-text' markdown="1">

[**Prototype-based Embedding Network for Scene Graph Generation.**](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Prototype-Based_Embedding_Network_for_Scene_Graph_Generation_CVPR_2023_paper.pdf) \\
C. Zheng, X. Lyu, **Lianli Gao**, B. Dai, and J. Song.\\
In _IEEE/CVF Conference on Computer Vision and Pattern Recognition_ (**CVPR**), pages 22783‚Äì22792, 2023\\
<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Prototype-Based_Embedding_Network_for_Scene_Graph_Generation_CVPR_2023_paper.pdf"><strong>Paper</strong></a>
\|
<a href="https://github.com/VL-Group/PENET"><strong>Code</strong></a>

**Acquiring robust features for reliable relation prediction in SGG.**

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/papers/7.png' alt="sym" width="100%" height="125%"></div></div>
<div class='paper-box-text' markdown="1">

[**Part-aware transformer for generalizable person re-identification.**](https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.pdf) \\
H. Ni, Y. Li, **Lianli Gao**, H. T. Shen, and J. Song.\\
In _IEEE/CVF International Conference on Computer Vision_ (**ICCV**), pages 11246‚Äì11255, 2023\\
<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.pdf"><strong>Paper</strong></a>
\|
<a href="https://github.com/liyuke65535/Part-Aware-Transformer"><strong>Code</strong></a>

**Mitagating domain-specific biases in Domain generalization person ReID.**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MM 2023</div><img src='images/papers/8.png' alt="sym" height="600" width="800"></div></div>
<div class='paper-box-text' markdown="1">

[**Moviefactory: Automatic movie creation from text using large generative models for language and images.**](https://arxiv.org/pdf/2306.07257.pdf) \\
 J. Zhu, H. Yang, H. He, W.Wang, Z. Tuo, W. Cheng, **Lianli Gao**, J. Song, and J. Fu. \\
In _Proceedings of the 31st ACM International Conference on Multimedia_ (**ACM MM**), pages 9313‚Äì9319, 2023\\
<a href="https://arxiv.org/pdf/2306.07257.pdf"><strong>Paper</strong></a>
\|
<a href="https://www.youtube.com/watch?v=tvDknhMFhzk"><strong>Demo</strong></a>

**Empowering users to create captivating movies using simple text inputs.**

</div>
</div>



- `TIP 2023` [From global to local: Multi-scale out-of-distribution detection.]([https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969654](https://arxiv.org/pdf/2308.10239.pdf)) J. Zhang, **Lianli Gao**, B. Hao, H. Huang, J. Song, and H. Shen. _IEEE Trans. Image Process.,_ 32:6115‚Äì6128, 2023. [Code](https://github.com/Koorye/DePT)
- `ICCV 2023` [DETA: denoised task adaptation for few-shot learning.](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf) J. Zhang, **Lianli Gao**, X. Luo, H. Shen, and J. Song. In _IEEE/CVF International Conference on Computer Vision, ICCV,_ pages 11507‚Äì11517, 2023. [Code](https://github.com/JimZAI/DETA)
- `TIP 2022` [Hierarchical representation network with auxiliary tasks for video captioning and video question answering.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9592722) **Lianli Gao**, Y. Lei, P. Zeng, J. Song, M. Wang, and H. T. Shen. _IEEE Trans. Image Process._, 31:202‚Äì215, 2022. [Code](https://github.com/riesling00/HRNAT)
- `TIP 2022` [Video question answering with prior knowledge and object-sensitive learning.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882977) P. Zeng, H. Zhang, **Lianli Gao**, J. Song, and H. T. Shen. _IEEE Trans. Image Process.,_ 31:5936‚Äì5948, 2022. [Code](https://github.com/zchoi/PKOL)
- `ECCV 2022` [State-aware compositional learning toward unbiased training for scene graph generation.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969654) T. He, **Lianli Gao**, J. Song, and Y. Li. _IEEE Trans. Image Process.,_ 32:43‚Äì56, 2023. [Code](https://lianligao.github.io/)
- `CVPR 2022` [Practical evaluation of adversarial robustness via adaptive auto attack.](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Practical_Evaluation_of_Adversarial_Robustness_via_Adaptive_Auto_Attack_CVPR_2022_paper.pdf) Y. Liu, Y. Cheng, **Lianli Gao**, X. Liu, Q. Zhang, and J. Song. In _IEEE/CVF Conference on Computer Vision and PatternRecognition, CVPR,_ pages 15084‚Äì15093, 2022. [Code](https://github.com/liuye6666/adaptive)
- `CVPR 2022` [Unified multivariate gaussian mixture for efficient neural image compression.](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_paper.pdf) X. Zhu, J. Song, **Lianli Gao**, F. Zheng, and H. T. Shen. In _IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR_, pages 17591‚Äì17600, 2022. [Code](https://github.com/xiaosu-zhu/McQuic)
- `CVPR 2022` [Fine-grained predicates learning for scene graph generation.](https://openaccess.thecvf.com/content/CVPR2022/papers/Lyu_Fine-Grained_Predicates_Learning_for_Scene_Graph_Generation_CVPR_2022_paper.pdf) X. Lyu, **Lianli Gao**, Y. Guo, Z. Zhao, H. Huang, H. T. Shen, and J. Song. In _IEEE/CVF Conference on Computer Vision and Pattern
Recognition, CVPR,_ pages 19445‚Äì19453, 2022. [Code](https://github.com/XinyuLyu/FGPL)
- `ECCV 2022` [Towards open-vocabulary scene graph generation with prompt-based finetuning.](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880055.pdf) T. He, **Lianli Gao**, J. Song, and Y. Li.  In _IEEE/CVF International Conference on Computer Vision, ICCV,_ pages 56‚Äì73, 2022. [Code](https://lianligao.github.io/)
- `ECCV 2022` [Frequency domain model augmentation for adversarial attack.](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640543.pdf) Long, Q. Zhang, B. Zeng, **Lianli Gao**, X. Liu, J. Zhang, and J. Song. In _IEEE/CVF International Conference on Computer Vision, ICCV,_ pages 549‚Äì566, 2022. [Code](https://github.com/yuyang-long/SSA)
- `ICLR 2022` [Beyond imagenet attack: Towards crafting adversarial examples for black-box domains.](https://arxiv.org/pdf/2201.11528.pdf) Q. Zhang, X. Li, Y. Chen, J. Song, **Lianli Gao**, Y. He, and H. Xue.  In _The Tenth International Conference on Learning Representations, ICLR,_ 2022. [Code](https://github.com/Alibaba-AAIG/Beyond-ImageNet-Attack)
- `NeurIPS 2022` [A differentiable semantic metric approximation in probabilistic embedding for cross-modal retrieval.](https://proceedings.neurips.cc/paper_files/paper/2022/file/4e786a87e7ae249de2b1aeaf5d8fde82-Paper-Conference.pdf) H. Li, J. Song, **Lianli Gao**, P. Zeng, H. Zhang, and G. Li.  In _Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems, NeurIPS,_ 2022. [Code](https://github.com/VL-Group/2022-NeurIPS-DAA)
- `NeurIPS 2022` [Natural color fool: Towards boosting black-box unrestricted attacks.](https://arxiv.org/pdf/2210.02041.pdf) S. Yuan, Q. Zhang, **Lianli Gao**, Y. Cheng, and J. Song. In _Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems, NeurIPS,_ 2022. [Code](https://github.com/VL-Group/Natural-Color-Fool)
- `NeurIPS 2022` [A lower bound of hash codes‚Äô performance.](https://arxiv.org/pdf/2210.05899.pdf) X. Zhu, J. Song, Y. Lei, **Lianli Gao**, and H. Shen. In _Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems, NeurIPS,_ 2022. [Code](https://github.com/vl-group/lbhash)
- `TPAMI 2020` [Hierarchical lstms with adaptive attention for visual captioning.](https://arxiv.org/pdf/1812.11004.pdf) **Lianli Gao**, X. Li, J. Song, and H. T. Shen. _IEEE Trans. Pattern Anal. Mach. Intell.,_ 42(5):1112‚Äì1131, 2020. [Code](https://github.com/lixiangpengcs/Spatial-Temporal-Adaptive-Attention-for-Video-Captioning)
<!-- under review -->

# üéñ Honors and Services
- **Research Honors:**
  - *2023* Rising Star of Science Award.
  - *2023*, *2020*, *2018* UESTC Research Excellence Award.
  - *2023*, *2018* UESTC Excellent Faculty Award for Teaching Excellence.
  - *2023* Chinese Young Female Scholars in Artificial Intelligence.
  - *2021* Sichuan Provincial Academic/Technical Leader (Reserve Candidate).
<!--   - *2020* IEEE Transactions on Multimedia Best Paper Award. -->
  - *2020* IEEE Technical Community on Multimedia Computing Rising Star Award.
  - *2019* Alibaba DAMO Academy Young Fellow Award.
  - *2017* Australasian Database Conference Best Student Paper Award.
- **Grand Challenges:**
  - *ECCV 2022:* DeeperAction Challenge 3rd place award on Track 4 Kinetics-TPS Challenge on Part-level Action Parsing.
  - *CVPR 2021:* Security AI Challenger Phrase VI Track 1st Place award in White-box Adversarial Attacks on ML Defense Models.
  - *ICCV 2021:* DeeperAction Challenge 3rd Place award on Track 3 Kinetics-TPS Challenge on Part-level Action Parsing.
  - *OPPO 2021:* Security Challenge 2nd Place award.
  - *ICCV 2019:* COCO DensePose Task Challenge 2nd place award.
- **Academic Services:**
  - *2025:* Senior program committee of AAAI 2025.
  - *2024:* ECCV Area Chair, WACV Area Chair, program committee of the IJCAI 24 track on AI and Social Good.
  - *2023:* WACV Area Chair
  - *2022:* AAAI SPC, WACV Area Chair
  - *2021:* ACM MM Session Chair, ACM MM Workshop Co-chair
  - *2019:* IJCAI Session Chair, Guest Editor of Journal of Visual Communication and Image Representation, etc.
  - *2018-Now:* Reviewers of IEEE TPAMI, TIP, TMM, TNNLS, TOC; IJCV; CVPR, ECCV, ICCV, AAAI, IJCAI, NeurIPS, ICML, MM, IJCAI and etc.


# üôã Supervisions
<!-- - *2019.05 - 2020.02*, [Lorem](https://github.com/), China.  -->
- **Current Ph.D students:**
  - Kaipeng Fang, Xiao Cai (Enrolled in _Jun. 2023_)
  - Xu Luo, Haonan Zhang (Enrolled in _Jun. 2022_)
  - Hao Ni, Sitong su (Enrolled in _Jun. 2021_)
  - Ji Zhang, Xinyu Lyu, and Juncheng Zhu (Enrolled in _Jun. 2020_)
  
- **Former Ph.D students:**
  - Tao He (Co-supervisor Monash University _Jun.2018 - Nov. 2022_)
    
    _Thesis: Towards Unbiased Scene Graph Generation: Techniques and Applications._
  - Xuanhang Wang (_Jun. 2019 - Jul. 2023_)
  
    _Thesis: Visual semantic understanding based visual dialogue._	
  - Pengpeng Zeng (_Jun. 2019 - Jul. 2023_)
  
    _Thesis: Research on Synergizing Vision and Text for Semantic Consistency Method._
  - Xiangpeng Li (_Jun.2018 - Jul. 2022_)
  
    _Thesis: Research on Visual Reasoning algorithm that integrates natural language analysis._
  - Yuyu Guo (_Jun. 2018 - Jul. 2022_)
	
	_Thesis: Visual Relationship Generation Based on Scene Understanding._

- **Current and former M.Sc. students:**
  - Hilali Sara Rita,Ke Liu, Mengqi Li, Shihan Wu, Fuwei Liu, and Lu Zhu (Enrolled in _Sep. 2022_)
  - Jiaqi Guo, Qisheng Chen, Youheng Sun, Yixin Qin, and Han Wang (Enrolled in _Sep. 2022_)
  - Durasic Aleksandra, Fuchun Wang, and Hao Wu (Enrolled in _Sep. 2021_)
  - Xiaoya Chen, Kai Xing, Jiahui Li, and Wenxue Shen (Graduated _Jun. 2023_)
  - Qike Zhao, Yaya Cheng, and Haoyu Wang (Graduated _Jun. 2022_)
  - Zhilong Zhou, Qian Ye, Hao He, and Ruiming Lang (Graduated _Jun. 2021_)
  - Qingsong Zhang, Liyang Zhang, and Ziming Fang (Graduated _Jun. 2020_)
  - Yuyu Guo (Graduated _Jun. 2019_)
  - Liangfu Cao (Graduated _Jun. 2018_)
  - Chuanshu Long (Graduated _Jun. 2017_)


# üíª Research Grants
 Some selective Research Grants: 
- *2024.01 - 2027.12*, Key Program of National Natural Science Foundation of China: ‚ÄúTrusted Big Cross-Meida Data Analysis and Key Technologies‚Äù, **Lead PI**
- *2022.01 - 2024.12*, Distinguished Young Scholars of the National Natural Science Foundation of China: ‚ÄúVisual Cognition by Integrating Natural Language‚Äù, **Lead PI**.
- *2019.01 - 2022.12*, General Program of National Natural Science Foundation of China: ‚ÄúDeep Visual Understanding by Fusing Natural Language Processing‚Äù, **Lead PI**. 
- *2016.01 - 2018.12*, Young Scientists Fund of the National Natural Science Foundation of China: ‚ÄúDeep Learning and Event Driven based Video Mashup‚Äù, **Lead PI**.

<!-- 
- *2020.12 - 2021.12*, **Lead PI** Fok Ying-Tong Education Foundation of China: ‚ÄúIntegrating Natural Language Processing for multimedia Understanding‚Äù, **Lead PI**.
- *2021.01 - 2024.12*, Ministry of Science and Technology of China, Major Project: ‚ÄúActive Monitoring, Cognition, and Searching for Disaster Environments‚Äù, **PI**.
 -->
